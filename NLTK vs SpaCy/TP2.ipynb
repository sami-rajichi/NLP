{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-weight: bold;\">TP2: Basic Text Processing</h1>\n",
    "<h3 style=\"font-weight: bold;\">Exercise</h3>\n",
    "<p>Using the NLTK (Natural Language Toolkit) package, we want to enrich the text (text.html) with a set of annotations such as the number of occurrences in the text, the lemma, the root, the grammatical category, etc. The result should be stored in a CSV file. Each line of the result file should contain the word and all the labels (see annotated_text.csv).</p>\n",
    "<p>Tasks to be completed:</p>\n",
    "<ul>\n",
    "  <li>Using regular expressions, filter the \"text.html\" file to remove tags and non-important information. Keep only the text.</li>\n",
    "  <li>Segment the resulting text into sentences.</li>\n",
    "  <li>Segment each sentence into words.</li>\n",
    "  <li>For each word, add the necessary labels according to the result file (see the \"annotated_text.csv\" file).</li>\n",
    "  <li>Repeat the same process, this time using the spaCy package.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocess Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    Reads and processes a text file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the file to be read.\n",
    "\n",
    "    Returns:\n",
    "        str : File content\n",
    "    \"\"\"\n",
    "    # Read the file and return a list of lines\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html>\\n\\t<head>\\n\\t\\t<meta charset=\"utf-8\"/>\\n\\t\\t<h1>\\n\\t\\t\\t<b> The Providence Journal</b>\\n\\t\\t</h1>\\n\\t</head>\\n\\t<body>\\n\\t\\t<text>\\n\\t\\t\\t<p>East Providence should organize its civil defense setup and begin by appointing a full-time director, Raymond H. Hawksley, the present city CD head, believes. Mr. Hawksley said yesterday he would be willing to go before the city council `` or anyone else locally \\'\\' to outline his proposal at the earliest possible time. East Providence now has no civil defense program. Mr. Hawksley, the state\\'s general treasurer, has been a part-time CD director in the city for the last nine years. He is not interested in being named a full-time director. </p>\\n\\t\\t\\t<p>Noting that President Kennedy has handed the Defense Department the major responsibility for the nation\\'s civil defense program, Mr. Hawksley said the federal government would pay half the salary of a full-time local director. He expressed the opinion the city could hire a CD director for about $3,500 a year and would only have to put up half that amount on a matching fund basis to defray the salary costs. </p>\\n\\t\\t\\t<p>Mr. Hawksley said he believed there are a number of qualified city residents who would be willing to take the full-time CD job. One of these men is former Fire Chief John A. Laughlin, he said. Along with a director, the city should provide a CD headquarters so that pertinent information about the local organization would be centralized. Mr. Hawksley said. One advantage that would come to the city in having a full-time director, he said, is that East Providence would become eligible to apply to the federal government for financial aid in purchasing equipment needed for a sound civil defense program. Matching funds also can be obtained for procurement of such items as radios, sirens and rescue trucks, he said. </p>\\n\\t\\t\\t<p>Mr. Hawksley believes that East Providence could use two more rescue trucks, similar to the CD vehicle obtained several years ago and now detailed to the Central Fire Station. He would assign one of the rescue trucks to the Riverside section of the city and the other to the Rumford area. Speaking of the present status of civil defense in the city, Mr. Hawksley said he would be willing to bet that not more than one person in a hundred would know what to do or where to go in the event of an enemy attack. </p>\\n\\t\\t</text>\\n\\t</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = read_file('./text.html')\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove HTML tags from a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing HTML tags.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with HTML tags removed.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "        \n",
    "    # Define a regular expression to match HTML tags\n",
    "    html_tags_pattern = re.compile(r'<.*?>')\n",
    "    \n",
    "    # Use the sub() function to replace HTML tags with an empty string\n",
    "    text_without_html = re.sub(html_tags_pattern, '', text)\n",
    "    \n",
    "    return text_without_html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t The Providence Journal\\n\\t\\t\\n\\t\\n\\t\\n\\t\\t\\n\\t\\t\\tEast Providence should organize its civil defense setup and begin by appointing a full-time director, Raymond H. Hawksley, the present city CD head, believes. Mr. Hawksley said yesterday he would be willing to go before the city council `` or anyone else locally '' to outline his proposal at the earliest possible time. East Providence now has no civil defense program. Mr. Hawksley, the state's general treasurer, has been a part-time CD director in the city for the last nine years. He is not interested in being named a full-time director. \\n\\t\\t\\tNoting that President Kennedy has handed the Defense Department the major responsibility for the nation's civil defense program, Mr. Hawksley said the federal government would pay half the salary of a full-time local director. He expressed the opinion the city could hire a CD director for about $3,500 a year and would only have to put up half that amount on a matching fund basis to defray the salary costs. \\n\\t\\t\\tMr. Hawksley said he believed there are a number of qualified city residents who would be willing to take the full-time CD job. One of these men is former Fire Chief John A. Laughlin, he said. Along with a director, the city should provide a CD headquarters so that pertinent information about the local organization would be centralized. Mr. Hawksley said. One advantage that would come to the city in having a full-time director, he said, is that East Providence would become eligible to apply to the federal government for financial aid in purchasing equipment needed for a sound civil defense program. Matching funds also can be obtained for procurement of such items as radios, sirens and rescue trucks, he said. \\n\\t\\t\\tMr. Hawksley believes that East Providence could use two more rescue trucks, similar to the CD vehicle obtained several years ago and now detailed to the Central Fire Station. He would assign one of the rescue trucks to the Riverside section of the city and the other to the Rumford area. Speaking of the present status of civil defense in the city, Mr. Hawksley said he would be willing to bet that not more than one person in a hundred would know what to do or where to go in the event of an enemy attack. \\n\\t\\t\\n\\t\\n\\n\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_without_tags = remove_html_tags(text=text)\n",
    "text_without_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_text_into_lines(text):\n",
    "    \"\"\"\n",
    "    Decompose a text into lines, removing empty lines and leading/trailing whitespace.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text to be decomposed into lines.\n",
    "\n",
    "    Returns:\n",
    "    list of str: A list of lines from the input text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the text into lines using newline as the delimiter\n",
    "    sentences = text.split('\\n')\n",
    "    \n",
    "    # Remove leading/trailing whitespace and empty lines\n",
    "    sentences = [s.replace('\\t', '').strip() for s in sentences if s.strip() != '']\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Providence Journal',\n",
       " \"East Providence should organize its civil defense setup and begin by appointing a full-time director, Raymond H. Hawksley, the present city CD head, believes. Mr. Hawksley said yesterday he would be willing to go before the city council `` or anyone else locally '' to outline his proposal at the earliest possible time. East Providence now has no civil defense program. Mr. Hawksley, the state's general treasurer, has been a part-time CD director in the city for the last nine years. He is not interested in being named a full-time director.\",\n",
       " \"Noting that President Kennedy has handed the Defense Department the major responsibility for the nation's civil defense program, Mr. Hawksley said the federal government would pay half the salary of a full-time local director. He expressed the opinion the city could hire a CD director for about $3,500 a year and would only have to put up half that amount on a matching fund basis to defray the salary costs.\",\n",
       " 'Mr. Hawksley said he believed there are a number of qualified city residents who would be willing to take the full-time CD job. One of these men is former Fire Chief John A. Laughlin, he said. Along with a director, the city should provide a CD headquarters so that pertinent information about the local organization would be centralized. Mr. Hawksley said. One advantage that would come to the city in having a full-time director, he said, is that East Providence would become eligible to apply to the federal government for financial aid in purchasing equipment needed for a sound civil defense program. Matching funds also can be obtained for procurement of such items as radios, sirens and rescue trucks, he said.',\n",
       " 'Mr. Hawksley believes that East Providence could use two more rescue trucks, similar to the CD vehicle obtained several years ago and now detailed to the Central Fire Station. He would assign one of the rescue trucks to the Riverside section of the city and the other to the Rumford area. Speaking of the present status of civil defense in the city, Mr. Hawksley said he would be willing to bet that not more than one person in a hundred would know what to do or where to go in the event of an enemy attack.']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = decompose_text_into_lines(text_without_tags)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NLTK vs SpaCy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    tag = tag[0].upper()\n",
    "    tag_dict = {\"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV, \"J\": wordnet.ADJ}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_text_with_nltk(sentences):\n",
    "    \"\"\"\n",
    "    Annotate text using NLTK for information like word, occurrences, lemma, stem, POS tag, and stopword status.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of sentences or text to be annotated.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing annotations, and also saves the annotations to an Excel file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize NLTK tools\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Initialize dictionaries to store annotations\n",
    "    annotations = {'word': [], 'occurrences': [], 'lemma': [], 'stem': [], 'pos_tag': [], 'is_stopword': []}\n",
    "    word_occurrence = {}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence\n",
    "        tokens = word_tokenize(sentence)\n",
    "\n",
    "        for token in tokens:\n",
    "            # Preprocess the token\n",
    "            token = token.lower()\n",
    "            token = ''.join(char for char in token if char.isalnum())\n",
    "\n",
    "            # Count word occurrences\n",
    "            word_occurrence[token] = word_occurrence.get(token, 1) + 1\n",
    "\n",
    "            if token == '' or token in annotations['word']:\n",
    "                continue\n",
    "\n",
    "            annotations['word'].append(token)\n",
    "            annotations['is_stopword'].append(token in stop_words)\n",
    "            pos_tag = nltk.pos_tag([token])[0][1]\n",
    "            annotations['pos_tag'].append(pos_tag)\n",
    "            annotations['lemma'].append(lemmatizer.lemmatize(token, get_wordnet_pos(pos_tag)))\n",
    "            annotations['stem'].append(stemmer.stem(token))\n",
    "\n",
    "    # Calculate word occurrences\n",
    "    for word in annotations['word']:\n",
    "        annotations['occurrences'].append(word_occurrence[word])\n",
    "\n",
    "    # Create a DataFrame from the annotations\n",
    "    annotations_df = pd.DataFrame(annotations)\n",
    "\n",
    "    # Save the annotations to an Excel file\n",
    "    annotations_df.to_excel('text_annotations_using_nltk.xlsx')\n",
    "\n",
    "    return annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurrences</th>\n",
       "      <th>lemma</th>\n",
       "      <th>stem</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>is_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>31</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>providence</td>\n",
       "      <td>6</td>\n",
       "      <td>providence</td>\n",
       "      <td>provid</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journal</td>\n",
       "      <td>2</td>\n",
       "      <td>journal</td>\n",
       "      <td>journal</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>east</td>\n",
       "      <td>5</td>\n",
       "      <td>east</td>\n",
       "      <td>east</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>should</td>\n",
       "      <td>3</td>\n",
       "      <td>should</td>\n",
       "      <td>should</td>\n",
       "      <td>MD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>where</td>\n",
       "      <td>2</td>\n",
       "      <td>where</td>\n",
       "      <td>where</td>\n",
       "      <td>WRB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>event</td>\n",
       "      <td>2</td>\n",
       "      <td>event</td>\n",
       "      <td>event</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>an</td>\n",
       "      <td>2</td>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "      <td>DT</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>enemy</td>\n",
       "      <td>2</td>\n",
       "      <td>enemy</td>\n",
       "      <td>enemi</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>attack</td>\n",
       "      <td>2</td>\n",
       "      <td>attack</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  occurrences       lemma     stem pos_tag  is_stopword\n",
       "0           the           31         the      the      DT         True\n",
       "1    providence            6  providence   provid      NN        False\n",
       "2       journal            2     journal  journal      NN        False\n",
       "3          east            5        east     east      NN        False\n",
       "4        should            3      should   should      MD         True\n",
       "..          ...          ...         ...      ...     ...          ...\n",
       "176       where            2       where    where     WRB         True\n",
       "177       event            2       event    event      NN        False\n",
       "178          an            2          an       an      DT         True\n",
       "179       enemy            2       enemy    enemi      NN        False\n",
       "180      attack            2      attack   attack      NN        False\n",
       "\n",
       "[181 rows x 6 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotate_text_with_nltk(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. SpaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_text_with_spacy(sentences):\n",
    "    \"\"\"\n",
    "    Annotate text using spaCy for information like word, occurrences, lemma, POS tag, and stopword status.\n",
    "\n",
    "    Parameters:\n",
    "    sentences (list): A list of sentences or text to be annotated.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing annotations, and also saves the annotations to an Excel file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the English language model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Initialize dictionaries to store annotations\n",
    "    annotations = {'word': [], 'occurrences': [], 'lemma': [], 'pos_tag': [], 'is_stopword': []}\n",
    "    word_occurrence = {}\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Process the text using spaCy\n",
    "        tokens = nlp(sentence)\n",
    "        for token in tokens:\n",
    "            word_occurrence[str(token).lower()] = word_occurrence.get(str(token).lower(), 1) + 1\n",
    "\n",
    "            if token.text == '' or token.text in annotations['word']:\n",
    "                continue\n",
    "\n",
    "            annotations['word'].append(str(token).lower())\n",
    "            annotations['is_stopword'].append(token.is_stop)\n",
    "            annotations['pos_tag'].append(token.pos_)\n",
    "            annotations['lemma'].append(token.lemma_)\n",
    "\n",
    "    # Calculate word occurrences\n",
    "    for word in annotations['word']:\n",
    "        annotations['occurrences'].append(word_occurrence[word])\n",
    "\n",
    "    # Create a DataFrame from the annotations\n",
    "    annotations_df = pd.DataFrame(annotations)\n",
    "\n",
    "    # Save the annotations to an Excel file\n",
    "    annotations_df.to_excel('text_annotations_using_spacy.xlsx')\n",
    "\n",
    "    return annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>occurrences</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>is_stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>31</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>providence</td>\n",
       "      <td>6</td>\n",
       "      <td>Providence</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journal</td>\n",
       "      <td>2</td>\n",
       "      <td>Journal</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>east</td>\n",
       "      <td>5</td>\n",
       "      <td>East</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>providence</td>\n",
       "      <td>6</td>\n",
       "      <td>Providence</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>where</td>\n",
       "      <td>2</td>\n",
       "      <td>where</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>event</td>\n",
       "      <td>2</td>\n",
       "      <td>event</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>an</td>\n",
       "      <td>2</td>\n",
       "      <td>an</td>\n",
       "      <td>DET</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>enemy</td>\n",
       "      <td>2</td>\n",
       "      <td>enemy</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>attack</td>\n",
       "      <td>2</td>\n",
       "      <td>attack</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  occurrences       lemma pos_tag  is_stopword\n",
       "0           the           31         the     DET         True\n",
       "1    providence            6  Providence   PROPN        False\n",
       "2       journal            2     Journal   PROPN        False\n",
       "3          east            5        East   PROPN        False\n",
       "4    providence            6  Providence   PROPN        False\n",
       "..          ...          ...         ...     ...          ...\n",
       "215       where            2       where   SCONJ         True\n",
       "216       event            2       event    NOUN        False\n",
       "217          an            2          an     DET         True\n",
       "218       enemy            2       enemy    NOUN        False\n",
       "219      attack            2      attack    NOUN        False\n",
       "\n",
       "[220 rows x 5 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotate_text_with_spacy(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Difference between NLTK and SpaCy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "  <tr>\n",
    "    <th>Feature</th>\n",
    "    <th>NLTK</th>\n",
    "    <th>spaCy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Tokenization</td>\n",
    "    <td>Word and sentence tokenization functions are available.</td>\n",
    "    <td>Advanced tokenization with word and sentence boundary detection.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Lemmatization</td>\n",
    "    <td>Basic lemmatization is available but may require additional custom rules.</td>\n",
    "    <td>Built-in lemmatization with WordNet integration and support for various languages.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Stemming</td>\n",
    "    <td>Provides stemming algorithms for English and other languages.</td>\n",
    "    <td>Lemmatization is provided, but stemming is not available in spaCy.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Part-of-Speech (POS) Tagging</td>\n",
    "    <td>Provides POS tagging but may require additional data for more languages.</td>\n",
    "    <td>Built-in POS tagging for multiple languages with pre-trained models.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Stopword Removal</td>\n",
    "    <td>Stopword lists are available, and removal can be customized.</td>\n",
    "    <td>Built-in stopword removal with support for multiple languages.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Named Entity Recognition (NER)</td>\n",
    "    <td>NER functionality is available but may require additional training for specific domains.</td>\n",
    "    <td>Built-in NER with support for various entity types and languages.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Dependency Parsing</td>\n",
    "    <td>Basic dependency parsing with customizable grammar rules.</td>\n",
    "    <td>Advanced dependency parsing with pre-trained models and efficient parsing algorithms.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Customization</td>\n",
    "    <td>NLTK allows you to define custom rules for various NLP tasks.</td>\n",
    "    <td>spaCy provides more advanced customization options, including training new models.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Community and Documentation</td>\n",
    "    <td>Has an active community and extensive documentation.</td>\n",
    "    <td>Has a growing community and comprehensive documentation.</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
