{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><b>TP 3: Language Model - Automatic Text Generation</b></h1></center>\n",
    "<h3><strong>Objective:</strong></h3>\n",
    "<p>We aim to generate text automatically using language models: N-grams. We rely on the NLTK package and its features to accomplish the task.</p>\n",
    "<h3><strong>Tasks to Accomplish:</strong></h3>\n",
    "<ol>\n",
    "    <li>Generate a single sentence automatically from a small corpus. Then, modify it to generate a paragraph composed of 10 sentences.</li>\n",
    "    <li>Modify the code to calculate the probability of each generated sentence by calculating its perplexity.</li>\n",
    "    <li>Generate a language model, this time based on morphosyntactic tags (use nltk or spaCy to obtain morphosyntactic tags), and verify the generated sentences based on this model.</li>\n",
    "    <li>Apply different N-gram language models to generate a paragraph composed of 10 sentences using \"the Reuters corpus\" as the training data.</li>\n",
    "    <li>Provide the perplexity values for each method and compare the results.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imported Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "from nltk import trigrams\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Customized Trigrams Language Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_trigrams_model(corpus=reuters.sents()):\n",
    "    \"\"\"\n",
    "    Create and fill a trigrams language model from a given corpus.\n",
    "\n",
    "    Args:\n",
    "        corpus (list of list of str): A list of sentences where each sentence is a list of words.\n",
    "\n",
    "    Returns:\n",
    "        dict: A trigrams language model represented as a nested dictionary.\n",
    "             The keys are tuples of the previous two words, and the values are dictionaries\n",
    "             where keys are possible next words and values are their frequencies.\n",
    "    \"\"\"\n",
    "    trigrams_model = {}\n",
    "\n",
    "    for sentence in corpus:\n",
    "        for token1, token2, token3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
    "            # Check if the first two tokens are in the model\n",
    "            if (token1, token2) not in trigrams_model:\n",
    "                trigrams_model[(token1, token2)] = {}\n",
    "\n",
    "            # Update the count of the third token\n",
    "            trigrams_model[(token1, token2)][token3] = trigrams_model[(token1, token2)].get(token3, 0) + 1\n",
    "\n",
    "    return trigrams_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model\n",
    "model = fill_trigrams_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_occurrences_to_probabilities(model):\n",
    "    \"\"\"\n",
    "    Transform token occurrences in a tri-gram model to probabilities.\n",
    "\n",
    "    Args:\n",
    "        model (dict): A bi-gram language model where keys are tuples of two words, and values are dictionaries\n",
    "            containing next-word occurrences.\n",
    "\n",
    "    Returns:\n",
    "        dict: The input model with occurrences transformed to probabilities.\n",
    "    \"\"\"\n",
    "    for bi_token in model:\n",
    "        total_count = sum(model[bi_token].values())\n",
    "\n",
    "        for token in model[bi_token]:\n",
    "            # Calculate the probability by dividing token count by the total count\n",
    "            model[bi_token][token] /= total_count\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transform_occurrences_to_probabilities(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elements_not_punctuation(model):\n",
    "    \"\"\"\n",
    "    Generate a tuple of start words that do not contain punctuation characters.\n",
    "\n",
    "    Args:\n",
    "        model (dict): A language model represented as a dictionary.\n",
    "\n",
    "    Returns:\n",
    "        list: A tuple of start words that do not contain punctuation characters.\n",
    "    \"\"\"\n",
    "    # Define a set of punctuation characters\n",
    "    punctuation_set = set(string.punctuation)\n",
    "\n",
    "    while True:\n",
    "        # Choose a random key (tuple of start words) from the model\n",
    "        start_words = list(random.choice(list(model.keys())))\n",
    "        \n",
    "        # Check if all words in the start words are not in the punctuation set\n",
    "        if all(word not in punctuation_set for word in start_words):\n",
    "            break\n",
    "\n",
    "    return start_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_with_trigram(model):\n",
    "    \"\"\"\n",
    "    Generate text using a trigram language model.\n",
    "\n",
    "    Args:\n",
    "        model (dict): A trigram language model represented as a nested dictionary.\n",
    "\n",
    "    Returns:\n",
    "        str: Generated text based on the trigram model.\n",
    "    \"\"\"\n",
    "    # Choose start words that do not contain punctuation\n",
    "    start_words = get_elements_not_punctuation(model=model)\n",
    "    \n",
    "    flag = False\n",
    "    while not flag:\n",
    "        text_threshold = random.choice(np.linspace(0, 1, num=10))\n",
    "        accumulator = 0.0\n",
    "        \n",
    "        for word in model[tuple(start_words[-2:])].keys():\n",
    "            accumulator += model[tuple(start_words[-2:])][word]\n",
    "            \n",
    "            if accumulator >= text_threshold:\n",
    "                start_words.append(word)\n",
    "                break\n",
    "        \n",
    "        # Check if the last two words are None (end of text)\n",
    "        if start_words[-2:] == [None] * 2:\n",
    "            flag = True\n",
    "    \n",
    "    return ' '.join([w for w in start_words if w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_morpho_syntax_model(generated_sentence):\n",
    "    \"\"\"\n",
    "    Generate morphosyntactic labels and map them to readable labels for a given sentence.\n",
    "\n",
    "    Args:\n",
    "        generated_sentence (str): The input sentence for which morphosyntactic labels are to be generated.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two elements.\n",
    "            - The first element is a string with morphosyntactic labels for each word in the sentence.\n",
    "            - The second element is a list of readable labels corresponding to the morphosyntactic labels.\n",
    "    \"\"\"\n",
    "    pos_tag_mapping = {\n",
    "        'CC': 'Coordinating Conj.',\n",
    "        'CD': 'Cardinal Num.',\n",
    "        'DT': 'Determiner',\n",
    "        'IN': 'Prep./Subj. Conj.',\n",
    "        'JJ': 'Adjective',\n",
    "        'JJR': 'Adj., Comp.',\n",
    "        'JJS': 'Adj., Sup.',\n",
    "        'MD': 'Modal',\n",
    "        'NN': 'Noun, Sing.',\n",
    "        'NNS': 'Noun, Plur.',\n",
    "        'NNP': 'Proper Noun, Sing.',\n",
    "        'NNPS': 'Proper Noun, Plur.',\n",
    "        'PRP': 'Personal Pronoun',\n",
    "        'RB': 'Adverb',\n",
    "        'RBR': 'Adv., Comp.',\n",
    "        'RBS': 'Adv., Sup.',\n",
    "        'VB': 'Verb, Base Form',\n",
    "        'VBD': 'Verb, Past Tense',\n",
    "        'VBG': 'Verb, Gerund/Pres. Part.',\n",
    "        'VBN': 'Verb, Past Part.',\n",
    "        'VBP': 'Verb, Non-3rd Sing. Pres.',\n",
    "        'VBZ': 'Verb, 3rd Sing. Pres.'\n",
    "    }\n",
    "    \n",
    "    # Tokenize the sentence into words\n",
    "    words = word_tokenize(generated_sentence)\n",
    "\n",
    "    # Perform part-of-speech tagging using NLTK\n",
    "    pos_tags = pos_tag(words)\n",
    "\n",
    "    # Map morphosyntactic labels to readable labels\n",
    "    readable_labels = [pos_tag_mapping.get(tag, tag) for word, tag in pos_tags]\n",
    "\n",
    "    # Join morphosyntactic labels into a string\n",
    "    morphosyntactic_labels = ' '.join([tag for word, tag in pos_tags])\n",
    "\n",
    "    return morphosyntactic_labels, readable_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stick_punctuation_to_word(text):\n",
    "    \"\"\"\n",
    "    Ensure that punctuation is properly attached to the preceding word in the text for improved readability.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with punctuation attached to words as needed.\n",
    "    \"\"\"\n",
    "    combined_list = []\n",
    "    word_list = text.split()\n",
    "    i = 0\n",
    "\n",
    "    while i < len(word_list):\n",
    "        if i < len(word_list) - 1 and word_list[i + 1] in string.punctuation:\n",
    "            # Combine the current word with the following punctuation\n",
    "            combined_word = word_list[i] + word_list[i + 1]\n",
    "            combined_list.append(combined_word)\n",
    "            i += 2\n",
    "        else:\n",
    "            # If no punctuation follows, add the word as-is\n",
    "            combined_list.append(word_list[i])\n",
    "            i += 1\n",
    "\n",
    "    # Join the combined words into a single text\n",
    "    return ' '.join([w for w in combined_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentence_perplexity(text, model):\n",
    "    \"\"\"\n",
    "    Calculate perplexity for a given text using a trigram language model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input sentence to calculate perplexity for.\n",
    "        model (dict): A trigram language model where keys are tuples of the previous two words,\n",
    "                     and values are dictionaries containing next-word probabilities.\n",
    "\n",
    "    Returns:\n",
    "        float: The calculated perplexity value for the input sentence.\n",
    "    \"\"\"\n",
    "    words = text.split()  # Tokenize the sentence\n",
    "    trigrams = [words[i:i + 3] for i in range(len(words) - 2)]\n",
    "\n",
    "    n = 0\n",
    "    perplexity_sum = 0.0\n",
    "\n",
    "    for trigram in trigrams:\n",
    "        if len(trigram) == 3:\n",
    "            w1, w2, w3 = trigram\n",
    "            probability = model.get(tuple([w1, w2]), {}).get(w3, 0.0)\n",
    "\n",
    "            if probability > 0:\n",
    "                perplexity_sum += math.log(1.0 / probability)\n",
    "                n += 1\n",
    "\n",
    "    if n == 0:\n",
    "        return float('inf')  # Avoid division by zero if no valid trigrams found\n",
    "\n",
    "    return math.exp(perplexity_sum / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_with_min_perplexity(sentences, perplexity_scores):\n",
    "    \"\"\"\n",
    "    Find the sentence with the minimum perplexity score from a list of sentences.\n",
    "\n",
    "    Args:\n",
    "        sentences (list of str): A list of sentences to choose from.\n",
    "        perplexity_scores (list of float): A list of perplexity scores corresponding to the sentences.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the sentence with the minimum perplexity score and the minimum perplexity score itself.\n",
    "               If the input data is invalid, it returns \"Invalid input data.\"\n",
    "    \"\"\"\n",
    "    if len(sentences) == 0 or len(sentences) != len(perplexity_scores):\n",
    "        return \"Invalid input data\"\n",
    "    \n",
    "    min_perplexity = min(perplexity_scores)\n",
    "    min_perplexity_index = perplexity_scores.index(min_perplexity)\n",
    "    \n",
    "    return sentences[min_perplexity_index], min_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(n=10, model=model):\n",
    "    \"\"\"\n",
    "    Generate text and calculate perplexity for multiple sentences.\n",
    "\n",
    "    Args:\n",
    "        n (int): The number of sentences to generate.\n",
    "        model (dict): The trigram language model for text generation.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    texts, perplexities = [], []\n",
    "\n",
    "    # Welcome message\n",
    "    print(f'#################\\tWelcome to the Simple Text Generator\\t#################')\n",
    "\n",
    "    for i in range(n):\n",
    "        print(f'>>> Text #{i+1}:')\n",
    "\n",
    "        # Generate text using the trigram model\n",
    "        generated_text = generate_text_with_trigram(model=model)\n",
    "        print(f'\\t+  {generated_text}')\n",
    "\n",
    "        # Annotate the generated text with morphosyntactic labels\n",
    "        annotated_text, readable_labels = generate_morpho_syntax_model(generated_text)\n",
    "        print(f'\\t+  {annotated_text}')\n",
    "\n",
    "        # Calculate and display perplexity\n",
    "        perplexity = calculate_sentence_perplexity(generated_text, model)\n",
    "        print(f'\\t+  PP({perplexity})')\n",
    "\n",
    "        print(f'++ Annotations:')\n",
    "        # Display annotations in a DataFrame\n",
    "        display(pd.DataFrame(data=[readable_labels], columns=annotated_text.split()))\n",
    "\n",
    "        texts.append(generated_text)\n",
    "        perplexities.append(perplexity)\n",
    "\n",
    "    print('--------------------------')\n",
    "\n",
    "    # Find the best generated text with the minimum perplexity\n",
    "    best_text, best_perplexity = get_sentence_with_min_perplexity(texts, perplexities)\n",
    "    print(f'ðŸŽ‰ðŸŽ‰ {stick_punctuation_to_word(best_text)} --- is the best generated text with PP({best_perplexity})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\tWelcome to the Simple Text Generator\t#################\n",
      ">>> Text #1:\n",
      "\t+  newspaper he saw the dollar could well be toughening our trade agreements ,\" Baker told the New York , for the last significant government reorganization in which Viner holds 408 , 766 FT - SE 100 at 4 . 91 dlrs Net profit 172 , 000 dlr tax credit but instead they chose something in international waters , it said .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t+  NN PRP VBD DT NN MD RB VB VBG PRP$ NN NNS , '' NNP VBD DT NNP NNP , IN DT JJ JJ NN NN IN WDT NNP VBZ CD , CD NNP : NN CD IN CD . CD JJ JJ NN CD , CD NNS NN NN CC RB PRP VBD NN IN JJ NNS , PRP VBD .\n",
      "\t+  PP(4.916927274483677)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>PRP</th>\n",
       "      <th>VBD</th>\n",
       "      <th>DT</th>\n",
       "      <th>NN</th>\n",
       "      <th>MD</th>\n",
       "      <th>RB</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBG</th>\n",
       "      <th>PRP$</th>\n",
       "      <th>...</th>\n",
       "      <th>PRP</th>\n",
       "      <th>VBD</th>\n",
       "      <th>NN</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>NNS</th>\n",
       "      <th>,</th>\n",
       "      <th>PRP</th>\n",
       "      <th>VBD</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Personal Pronoun</td>\n",
       "      <td>Verb, Past Tense</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Modal</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>Verb, Base Form</td>\n",
       "      <td>Verb, Gerund/Pres. Part.</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>...</td>\n",
       "      <td>Personal Pronoun</td>\n",
       "      <td>Verb, Past Tense</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>,</td>\n",
       "      <td>Personal Pronoun</td>\n",
       "      <td>Verb, Past Tense</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            NN               PRP               VBD          DT           NN  \\\n",
       "0  Noun, Sing.  Personal Pronoun  Verb, Past Tense  Determiner  Noun, Sing.   \n",
       "\n",
       "      MD      RB               VB                       VBG  PRP$  ...  \\\n",
       "0  Modal  Adverb  Verb, Base Form  Verb, Gerund/Pres. Part.  PRP$  ...   \n",
       "\n",
       "                PRP               VBD           NN                 IN  \\\n",
       "0  Personal Pronoun  Verb, Past Tense  Noun, Sing.  Prep./Subj. Conj.   \n",
       "\n",
       "          JJ          NNS  ,               PRP               VBD  .  \n",
       "0  Adjective  Noun, Plur.  ,  Personal Pronoun  Verb, Past Tense  .  \n",
       "\n",
       "[1 rows x 62 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Text #2:\n",
      "\t+  Jose Melicias from the Federal Reserve and 9 . 60 dlrs a share .\n",
      "\t+  NNP NNP IN DT NNP NNP CC CD . CD NN DT NN .\n",
      "\t+  PP(5.800437217242906)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNP</th>\n",
       "      <th>NNP</th>\n",
       "      <th>IN</th>\n",
       "      <th>DT</th>\n",
       "      <th>NNP</th>\n",
       "      <th>NNP</th>\n",
       "      <th>CC</th>\n",
       "      <th>CD</th>\n",
       "      <th>.</th>\n",
       "      <th>CD</th>\n",
       "      <th>NN</th>\n",
       "      <th>DT</th>\n",
       "      <th>NN</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>Coordinating Conj.</td>\n",
       "      <td>Cardinal Num.</td>\n",
       "      <td>.</td>\n",
       "      <td>Cardinal Num.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NNP                 NNP                 IN          DT  \\\n",
       "0  Proper Noun, Sing.  Proper Noun, Sing.  Prep./Subj. Conj.  Determiner   \n",
       "\n",
       "                  NNP                 NNP                  CC             CD  \\\n",
       "0  Proper Noun, Sing.  Proper Noun, Sing.  Coordinating Conj.  Cardinal Num.   \n",
       "\n",
       "   .             CD           NN          DT           NN  .  \n",
       "0  .  Cardinal Num.  Noun, Sing.  Determiner  Noun, Sing.  .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Text #3:\n",
      "\t+  Brazil withdrawing from the bottoming out of the report took no account of Singapore rubber market because of better European demand and undertaking necessary economic restructuring away from an 80 pct of the franchise banks that were better managed have gotten a boost in production .\n",
      "\t+  NNP VBG IN DT VBG IN IN DT NN VBD DT NN IN NNP NN NN IN IN JJR JJ NN CC JJ JJ JJ NN RB IN DT CD NN IN DT NN NNS WDT VBD JJR VBN VBP VBN DT NN IN NN .\n",
      "\t+  PP(6.032768144919998)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NNP</th>\n",
       "      <th>VBG</th>\n",
       "      <th>IN</th>\n",
       "      <th>DT</th>\n",
       "      <th>VBG</th>\n",
       "      <th>IN</th>\n",
       "      <th>IN</th>\n",
       "      <th>DT</th>\n",
       "      <th>NN</th>\n",
       "      <th>VBD</th>\n",
       "      <th>...</th>\n",
       "      <th>VBD</th>\n",
       "      <th>JJR</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBN</th>\n",
       "      <th>DT</th>\n",
       "      <th>NN</th>\n",
       "      <th>IN</th>\n",
       "      <th>NN</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>Verb, Gerund/Pres. Part.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Verb, Gerund/Pres. Part.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Verb, Past Tense</td>\n",
       "      <td>...</td>\n",
       "      <td>Verb, Past Tense</td>\n",
       "      <td>Adj., Comp.</td>\n",
       "      <td>Verb, Past Part.</td>\n",
       "      <td>Verb, Non-3rd Sing. Pres.</td>\n",
       "      <td>Verb, Past Part.</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NNP                       VBG                 IN  \\\n",
       "0  Proper Noun, Sing.  Verb, Gerund/Pres. Part.  Prep./Subj. Conj.   \n",
       "\n",
       "           DT                       VBG                 IN                 IN  \\\n",
       "0  Determiner  Verb, Gerund/Pres. Part.  Prep./Subj. Conj.  Prep./Subj. Conj.   \n",
       "\n",
       "           DT           NN               VBD  ...               VBD  \\\n",
       "0  Determiner  Noun, Sing.  Verb, Past Tense  ...  Verb, Past Tense   \n",
       "\n",
       "           JJR               VBN                        VBP               VBN  \\\n",
       "0  Adj., Comp.  Verb, Past Part.  Verb, Non-3rd Sing. Pres.  Verb, Past Part.   \n",
       "\n",
       "           DT           NN                 IN           NN  .  \n",
       "0  Determiner  Noun, Sing.  Prep./Subj. Conj.  Noun, Sing.  .  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Text #4:\n",
      "\t+  impose curbs on U . S . Oil acreage writedown .\n",
      "\t+  JJ NNS IN NNP . NNP . NNP NN NN .\n",
      "\t+  PP(3.351774773462404)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JJ</th>\n",
       "      <th>NNS</th>\n",
       "      <th>IN</th>\n",
       "      <th>NNP</th>\n",
       "      <th>.</th>\n",
       "      <th>NNP</th>\n",
       "      <th>.</th>\n",
       "      <th>NNP</th>\n",
       "      <th>NN</th>\n",
       "      <th>NN</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adjective</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>.</td>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>.</td>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          JJ          NNS                 IN                 NNP  .  \\\n",
       "0  Adjective  Noun, Plur.  Prep./Subj. Conj.  Proper Noun, Sing.  .   \n",
       "\n",
       "                  NNP  .                 NNP           NN           NN  .  \n",
       "0  Proper Noun, Sing.  .  Proper Noun, Sing.  Noun, Sing.  Noun, Sing.  .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Text #5:\n",
      "\t+  Should work closely within the LDP ' s credibility , Shiratori told Reuters earlier this week for 2 . 193 mln ounces of gold producers .\n",
      "\t+  MD VB RB IN DT NNP POS NN NN , NNP VBD NNPS RBR DT NN IN CD . CD JJ NNS IN NN NNS .\n",
      "\t+  PP(6.54853517477716)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MD</th>\n",
       "      <th>VB</th>\n",
       "      <th>RB</th>\n",
       "      <th>IN</th>\n",
       "      <th>DT</th>\n",
       "      <th>NNP</th>\n",
       "      <th>POS</th>\n",
       "      <th>NN</th>\n",
       "      <th>NN</th>\n",
       "      <th>,</th>\n",
       "      <th>...</th>\n",
       "      <th>IN</th>\n",
       "      <th>CD</th>\n",
       "      <th>.</th>\n",
       "      <th>CD</th>\n",
       "      <th>JJ</th>\n",
       "      <th>NNS</th>\n",
       "      <th>IN</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modal</td>\n",
       "      <td>Verb, Base Form</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>POS</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>,</td>\n",
       "      <td>...</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Cardinal Num.</td>\n",
       "      <td>.</td>\n",
       "      <td>Cardinal Num.</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MD               VB      RB                 IN          DT  \\\n",
       "0  Modal  Verb, Base Form  Adverb  Prep./Subj. Conj.  Determiner   \n",
       "\n",
       "                  NNP  POS           NN           NN  ,  ...  \\\n",
       "0  Proper Noun, Sing.  POS  Noun, Sing.  Noun, Sing.  ,  ...   \n",
       "\n",
       "                  IN             CD  .             CD         JJ          NNS  \\\n",
       "0  Prep./Subj. Conj.  Cardinal Num.  .  Cardinal Num.  Adjective  Noun, Plur.   \n",
       "\n",
       "                  IN           NN          NNS  .  \n",
       "0  Prep./Subj. Conj.  Noun, Sing.  Noun, Plur.  .  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Text #6:\n",
      "\t+  000 francs .\n",
      "\t+  CD NNS .\n",
      "\t+  PP(1.5)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CD</th>\n",
       "      <th>NNS</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cardinal Num.</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CD          NNS  .\n",
       "0  Cardinal Num.  Noun, Plur.  ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Text #7:\n",
      "\t+  smuggled from Miami .\n",
      "\t+  VBN IN NNP .\n",
      "\t+  PP(1.414213562373095)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VBN</th>\n",
       "      <th>IN</th>\n",
       "      <th>NNP</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Verb, Past Part.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                VBN                 IN                 NNP  .\n",
       "0  Verb, Past Part.  Prep./Subj. Conj.  Proper Noun, Sing.  ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Text #8:\n",
      "\t+  cash dividends on its proposed refinancing packages , with annual capacity of 4 . 1 mln Avg shrs 1 , 512 Revs 7 , 800 hectares , or 76 cts vs 56 . 4p , a departure from the Sosnoff move for quite some time .\n",
      "\t+  NN NNS IN PRP$ VBN NN NNS , IN JJ NN IN CD . CD JJ NNP NN CD , CD NNP CD , CD NNS , CC CD NNS JJ CD . CD , DT NN IN DT NNP NN IN RB DT NN .\n",
      "\t+  PP(7.66699166615273)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>IN</th>\n",
       "      <th>PRP$</th>\n",
       "      <th>VBN</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>,</th>\n",
       "      <th>IN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>...</th>\n",
       "      <th>NN</th>\n",
       "      <th>IN</th>\n",
       "      <th>DT</th>\n",
       "      <th>NNP</th>\n",
       "      <th>NN</th>\n",
       "      <th>IN</th>\n",
       "      <th>RB</th>\n",
       "      <th>DT</th>\n",
       "      <th>NN</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>Verb, Past Part.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>,</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Adjective</td>\n",
       "      <td>...</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Proper Noun, Sing.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Prep./Subj. Conj.</td>\n",
       "      <td>Adverb</td>\n",
       "      <td>Determiner</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            NN          NNS                 IN  PRP$               VBN  \\\n",
       "0  Noun, Sing.  Noun, Plur.  Prep./Subj. Conj.  PRP$  Verb, Past Part.   \n",
       "\n",
       "            NN          NNS  ,                 IN         JJ  ...  \\\n",
       "0  Noun, Sing.  Noun, Plur.  ,  Prep./Subj. Conj.  Adjective  ...   \n",
       "\n",
       "            NN                 IN          DT                 NNP  \\\n",
       "0  Noun, Sing.  Prep./Subj. Conj.  Determiner  Proper Noun, Sing.   \n",
       "\n",
       "            NN                 IN      RB          DT           NN  .  \n",
       "0  Noun, Sing.  Prep./Subj. Conj.  Adverb  Determiner  Noun, Sing.  .  \n",
       "\n",
       "[1 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Text #9:\n",
      "\t+  based auto parts .\n",
      "\t+  VBN NN NNS .\n",
      "\t+  PP(2.449489742783178)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VBN</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Verb, Past Part.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                VBN           NN          NNS  .\n",
       "0  Verb, Past Part.  Noun, Sing.  Noun, Plur.  ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Text #10:\n",
      "\t+  moving expenses , most commodity prices , sources said .\n",
      "\t+  VBG NNS , JJS NN NNS , NNS VBD .\n",
      "\t+  PP(6.045793824049856)\n",
      "++ Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VBG</th>\n",
       "      <th>NNS</th>\n",
       "      <th>,</th>\n",
       "      <th>JJS</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>,</th>\n",
       "      <th>NNS</th>\n",
       "      <th>VBD</th>\n",
       "      <th>.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Verb, Gerund/Pres. Part.</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>,</td>\n",
       "      <td>Adj., Sup.</td>\n",
       "      <td>Noun, Sing.</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>,</td>\n",
       "      <td>Noun, Plur.</td>\n",
       "      <td>Verb, Past Tense</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        VBG          NNS  ,         JJS           NN  \\\n",
       "0  Verb, Gerund/Pres. Part.  Noun, Plur.  ,  Adj., Sup.  Noun, Sing.   \n",
       "\n",
       "           NNS  ,          NNS               VBD  .  \n",
       "0  Noun, Plur.  ,  Noun, Plur.  Verb, Past Tense  .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "ðŸŽ‰ðŸŽ‰ smuggled from Miami. --- is the best generated text with PP(1.414213562373095)\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "generate_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **N-grams Language Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE, Laplace, KneserNeyInterpolated, Lidstone\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ngram_model(n, model_type, corpus):\n",
    "    \"\"\"\n",
    "    Train an n-gram language model on a given corpus.\n",
    "\n",
    "    Args:\n",
    "        n (int): The order of the n-gram model.\n",
    "        model_type (str): The type of language model to train ('mle', 'laplace', 'kneser-ney', or 'lidstone').\n",
    "        corpus (list of list of str): A list of sentences where each sentence is a list of words.\n",
    "\n",
    "    Returns:\n",
    "        nltk.lm.LmModel: The trained n-gram language model of the specified type.\n",
    "    \"\"\"\n",
    "    # Create padded everygram model\n",
    "    train, vocab = padded_everygram_pipeline(n, corpus)\n",
    "\n",
    "    # Select the model type and initialize the model\n",
    "    if model_type == 'mle':\n",
    "        model = MLE(n)\n",
    "    elif model_type == 'laplace':\n",
    "        model = Laplace(n)\n",
    "    elif model_type == 'kneser-ney':\n",
    "        model = KneserNeyInterpolated(n, discount=0.1)\n",
    "    elif model_type == 'lidstone':\n",
    "        model = Lidstone(0.5, n)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Use 'mle', 'lidstone', 'laplace', or 'kneser-ney'.\")\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    model.fit(train, vocab)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elements_not_punctuation(vocab):\n",
    "    \"\"\"\n",
    "    Generate a sequence of words that do not contain punctuation characters.\n",
    "\n",
    "    Args:\n",
    "        vocab (list of str): A vocabulary list from which to choose a sequence of words.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A sequence of words that do not contain punctuation characters.\n",
    "    \"\"\"\n",
    "    # Define a set of punctuation characters and digits\n",
    "    punctuation_set = set(string.punctuation)\n",
    "\n",
    "    while True:\n",
    "        start_words = random.choice(vocab)\n",
    "\n",
    "        # Check if all words in the chosen sequence are not in the punctuation set\n",
    "        if all(word not in punctuation_set for word in start_words):\n",
    "            break\n",
    "\n",
    "    return start_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraph(model, num_phrases):\n",
    "    \"\"\"\n",
    "    Generate a paragraph composed of multiple phrases using an n-gram language model.\n",
    "\n",
    "    Args:\n",
    "        model (nltk.lm.LmModel): The trained n-gram language model.\n",
    "        num_phrases (int): The number of phrases to generate in the paragraph.\n",
    "\n",
    "    Returns:\n",
    "        list of str: A list of phrases forming the generated paragraph.\n",
    "    \"\"\"\n",
    "    paragraph = []\n",
    "\n",
    "    for _ in range(num_phrases):\n",
    "        current_word = get_elements_not_punctuation(list(model.vocab))  # Initialize current_word\n",
    "        \n",
    "        # Generate the next words in the phrase\n",
    "        next_words = model.generate(15, text_seed=[current_word], random_seed=3)\n",
    "\n",
    "        # Join the generated words to form a phrase\n",
    "        phrase = ' '.join(next_words)\n",
    "        paragraph.append(phrase)\n",
    "\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_perplexity_entropy(model, text):\n",
    "    \"\"\"\n",
    "    Calculate perplexity and entropy for a given text using an n-gram language model.\n",
    "\n",
    "    Args:\n",
    "        model (nltk.lm.LmModel): The n-gram language model.\n",
    "        text (str): The text for which to calculate perplexity and entropy.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two values.\n",
    "            - The first value is the perplexity of the text based on the model.\n",
    "            - The second value is the entropy of the text based on the model.\n",
    "    \"\"\"\n",
    "    return model.perplexity(text), model.entropy(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_generation(model='mle'):\n",
    "    \"\"\"\n",
    "    Generate a paragraph using an n-gram language model and calculate perplexity and entropy.\n",
    "\n",
    "    Args:\n",
    "        model (str): The type of language model to train ('mle', 'laplace', 'kneser-ney', or 'lidstone').\n",
    "                     Defaults to 'mle'.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    corpus = reuters.sents()\n",
    "    n = 2  # You can change n to 1, 2, or 3 for unigram, bigram, or trigram models\n",
    "\n",
    "    # Train an n-gram language model on the corpus\n",
    "    ngram_model = train_ngram_model(n, model, corpus)\n",
    "    \n",
    "    num_phrases = 10\n",
    "\n",
    "    # Generate a paragraph using the trained model\n",
    "    generated_paragraph = generate_paragraph(ngram_model, num_phrases)\n",
    "\n",
    "    # Calculate perplexity and entropy for the generated paragraph\n",
    "    perplexity, entropy = calculate_perplexity_entropy(ngram_model, ' '.join(generated_paragraph))\n",
    "\n",
    "    print(f\"Generated Paragraph with {n}-grams {model} model:\")\n",
    "    for i, phrase in enumerate(generated_paragraph):\n",
    "        print(f\"Phrase {i + 1}: {phrase}\")\n",
    "\n",
    "    print(f\"Perplexity ({model}): {perplexity}\\nCross-entropy ({model}): {entropy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Paragraph with 2-grams mle model:\n",
      "Phrase 1: . </s> Net excludes gains . 0 mln Year Oper shr and tax gain of\n",
      "Phrase 2: Program for breaking safety of 1987 , the afternoon , with each share cash for\n",
      "Phrase 3: , argue that personal income . 0 mln Year Oper shr and tax gain of\n",
      "Phrase 4: . </s> Net excludes gains . 0 mln Year Oper shr and tax gain of\n",
      "Phrase 5: . </s> Net excludes gains . 0 mln Year Oper shr and tax gain of\n",
      "Phrase 6: Nederland NV & lt ; ATRC . </s> <s> Cash surplus in the exchange rate\n",
      "Phrase 7: and has been one of 1987 , the afternoon , with each share cash for\n",
      "Phrase 8: ENQUIRY INTO HONG KONG FIRM AGREES COCOA SURPLUS 94 . semiconductor makers to end of\n",
      "Phrase 9: had included an immediate outlook , 000 vs 2 , with each share cash for\n",
      "Phrase 10: well as dollar had no assurance . </s> <s> Cash surplus in the exchange rate\n",
      "Perplexity (mle): inf\n",
      "Cross-entropy (mle): inf\n",
      "--------------\n",
      "Generated Paragraph with 2-grams laplace model:\n",
      "Phrase 1: are made considerable number of 2 , such as a year ago protected convoy of\n",
      "Phrase 2: Hovis said Huckaby said it added , such as a year ago protected convoy of\n",
      "Phrase 3: de Macedo told journalists in 1986 , such as a year ago protected convoy of\n",
      "Phrase 4: - date demand for oil . 0 mln Year Oper shr after the entire net\n",
      "Phrase 5: , and author of legislators , 000 vs 2 - year ago protected convoy of\n",
      "Phrase 6: & lt ; Midland Co & lt ; DASA > will encourage saving on producer\n",
      "Phrase 7: and general fall in one - 1 mln Year Oper shr after the entire net\n",
      "Phrase 8: without jeopardising the latest move . 0 mln Year Oper shr after the entire net\n",
      "Phrase 9: Inc eye of its money . 0 mln Year Oper shr after the entire net\n",
      "Phrase 10: AG 10 . </s> goods , 000 vs 2 - year ago protected convoy of\n",
      "Perplexity (laplace): 76391.14604114904\n",
      "Cross-entropy (laplace): 16.221117814894967\n",
      "--------------\n",
      "Generated Paragraph with 2-grams lidstone model:\n",
      "Phrase 1: in implementing some markets here , 000 vs 2 - year ago period by mid\n",
      "Phrase 2: & lt ; Merrill Lynch ........ 18 dlrs Net 212 tonnes grain storage facilities in\n",
      "Phrase 3: ,\" he produced from evaluating a 1 mln Year Oper shr and streamlining operations mainly\n",
      "Phrase 4: BY INVESTOR GROUP INC & lt ; SULPETRO LOSS Multi - apartheid system could not\n",
      "Phrase 5: ' s cultural industries fell 0 - seasonally adjusted 536 vs 4 mln dlrs in\n",
      "Phrase 6: - day and it raised 50 , that branches are worried about six major nations\n",
      "Phrase 7: Gancia , Centralia and limit . 0 mln Year Oper shr and streamlining operations mainly\n",
      "Phrase 8: . </s> Net Loss continuing U . Agriculture Department estimated world group said electricians came\n",
      "Phrase 9: > SELLS HEINOLD HOG AND BEAR > had been curtailed unless it was incorrect .\n",
      "Phrase 10: and growers are not mean a 1 mln Year Oper shr and streamlining operations mainly\n",
      "Perplexity (lidstone): 58561.98247369996\n",
      "Cross-entropy (lidstone): 15.837676772935136\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "for model in ['mle', 'laplace', 'lidstone']: # I don't have high-performing hardware resources to handle Kneser-Ney model, so not going to try it\n",
    "    start_generation(model=model)\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kneser-Ney smoothing model is a more complex and computationally intensive language modeling technique compared to simpler models like Maximum Likelihood Estimation (MLE) or Laplace smoothing. The reason the Kneser-Ney model may take longer to execute is because it involves additional calculations to estimate and smooth n-gram probabilities. Here are some factors that contribute to its longer execution time:\n",
    "\n",
    "1. **Interpolation and Back-off:** Kneser-Ney smoothing uses both interpolation and back-off techniques, which require estimating and combining probabilities from various n-grams. This involves additional calculations and data structures to manage these probabilities.\n",
    "\n",
    "2. **Discounting**: Kneser-Ney uses discounting to redistribute probability mass from higher-order n-grams to lower-order n-grams. Calculating and applying these discounting factors can be computationally intensive, especially for larger n-gram models.\n",
    "\n",
    "3. **Vocabulary Size**: The size of the vocabulary in the corpus can impact the execution time. Kneser-Ney may involve handling a larger number of n-grams and vocabulary entries, leading to increased computational overhead.\n",
    "\n",
    "4. **Data Structures**: The Kneser-Ney model may use more complex data structures to store and manage n-gram information, which can contribute to longer execution times.\n",
    "\n",
    "5. **Complexity**: The Kneser-Ney model's mathematical complexity, involving recursive calculations and multiple adjustments, adds to the computational workload."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
